# -*- coding: utf-8 -*-
"""DiabitiesPrediction.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1pFSnbAtYruAz5gChoy8Jm6wTimfUCoo0

Diabities
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sas
import numpy as np

df=pd.read_csv('/content/diabetes_data_upload.csv')
df[0:4]

#Changing the column name for our understanding
df.rename({'Polyuria':'Excessive Urination','Polydipsia':'Excessive Thirst','Polyphagia':'Feeling Excessive Hungary','partial paresis':'Muscle weakness','Alopecia':'Hair Loss'},axis=1,inplace=True)

"""EDA"""

#Check for the data info
print(df.info())
#Check for any null values in any column
print(df.isnull().sum())

#Check for the rows that contain the NaN values
df[df.isna().any(axis=1)]

#Based on the certain age on what frequency of high chance of diabities
Frequency_Count=df.groupby('Age')['class'].value_counts().unstack().reset_index() #Unstack() is used to pivot or reshape the data
Frequency_Count_melted = Frequency_Count.melt(id_vars='Age', value_vars=['Negative', 'Positive'], var_name='class', value_name='Frequency').dropna()

plt.figure(figsize=(12,7))
sas.barplot(data=Frequency_Count_melted,x='Age',y='Frequency',hue='class',palette='viridis')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.title('Frequency of Diabetes Class by Age')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

#Between male and female what is the percentage of getting diabities
Gender_Count=df.groupby('Gender')['class'].value_counts().unstack().reset_index()
Gender_Count_melted=Gender_Count.melt(id_vars='Gender',value_vars=['Negative','Positive'],var_name='class',value_name='Frequency').dropna()
plt.figure(figsize=(12,7))
sas.barplot(data=Gender_Count_melted,x='Gender',y='Frequency',hue='class',palette='viridis')
plt.xlabel('Gender')
plt.ylabel('Frequency')
plt.title('Frequency of Diabetes Class by Gender')
plt.xticks(rotation=90)

df[0:4]

#Covert the all tesxt data intp numberic for model prediction
from sklearn.preprocessing import LabelEncoder
le=LabelEncoder()
Data=df[['Gender','Excessive Urination','Excessive Thirst','sudden weight loss','weakness','Feeling Excessive Hungary','Genital thrush','visual blurring','Itching','Irritability','delayed healing','Muscle weakness','muscle stiffness','Hair Loss','Obesity']].apply(le.fit_transform)
Data['Age']=df['Age']
Data['class']=df['class']
Data[0:4]

#Rescale the data so that we can use it in the model.
from sklearn.preprocessing import StandardScaler
sc=StandardScaler()
Data_Scaled=sc.fit_transform(Data.drop('class',axis=1))
Data_Scaled

"""Logestic Regression"""

#Split the data
X=Data_Scaled
Y=Data['class']
from sklearn.model_selection import train_test_split
X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=42)

#Model building
from sklearn.linear_model import LogisticRegression
lr=LogisticRegression()
lr.fit(X_train,y_train)
y_pred=lr.predict(X_test)

#Actual and Predicted value
Actual_Predicted=pd.DataFrame({'Actual':y_test,'Predicted':y_pred}).reset_index(drop=True)
Actual_Predicted

#Check the accuracy of the model
from sklearn.metrics import accuracy_score,confusion_matrix,classification_report
print(accuracy_score(y_test,y_pred)*100)

#Now print the Confusion matrix
print(confusion_matrix(y_test,y_pred))
sas.heatmap(confusion_matrix(y_test,y_pred),annot=True,fmt='d')

"""True Positive (28)= The model correctly predict the positive outcome.

False Positive (5) =The model incorrectly predict something as positive (Type I error).

True Negative (3) = The model will correctly predict the negative ones.

False Negative (68) =The model miss the positive and predict as a negative (Type II error).

Model Deployment
"""

!pip install streamlit

from sklearn.linear_model import LogisticRegression
import streamlit as st
import pandas as pd
from sklearn.model_selection import train_test_split


st.title('ðŸ©¸Diabetes Prediction')
st.sidebar.header('User Input Features')

def user_input_parameters():
  AGE=st.sidebar.number_input('Age',1,100)
  GENDER=st.sidebar.selectbox('Gender',('Male','Female'))
  GENDER=1 if GENDER=='Male' else 0
  EXCESSIVE_URINATION=st.sidebar.selectbox('Excessive Urination',('Yes','No'))
  EXCESSIVE_URINATION=1 if EXCESSIVE_URINATION=='Yes' else 0
  EXCESSIVE_THIRST=st.sidebar.selectbox('Excessive Thirst',('Yes','No'))
  EXCESSIVE_THIRST=1 if EXCESSIVE_THIRST=='Yes' else 0
  SUDDEN_WEIGHT_LOSS=st.sidebar.selectbox('Sudden Weight Loss',('Yes','No'))
  SUDDEN_WEIGHT_LOSS=1 if SUDDEN_WEIGHT_LOSS=='Yes' else 0
  WEAKNESS=st.sidebar.selectbox('Weakness',('Yes','No'))
  WEAKNESS=1 if WEAKNESS=='Yes' else 0
  FEELING_EXCESSIVE_HUNGER=st.sidebar.selectbox('Feeling Excessive Hunger',('Yes','No'))
  FEELING_EXCESSIVE_HUNGER=1 if FEELING_EXCESSIVE_HUNGER=='Yes' else 0
  VISUAL_BLURING=st.sidebar.selectbox('Visual Blurring',('Yes','No'))
  VISUAL_BLURING=1 if VISUAL_BLURING=='Yes' else 0
  HAIR_LOSS=st.sidebar.selectbox('Hair Loss',('Yes','No'))
  HAIR_LOSS=1 if HAIR_LOSS=='Yes' else 0
  data={'Age':AGE,'Gender':GENDER,'Excessive Urination':EXCESSIVE_URINATION,
        'Excessive Thirst':EXCESSIVE_THIRST,'sudden weight loss':SUDDEN_WEIGHT_LOSS,
        'weakness':WEAKNESS,'Feeling Excessive Hungary':FEELING_EXCESSIVE_HUNGER,'visual blurring':VISUAL_BLURING,'Hair Loss':HAIR_LOSS}
  feature=pd.DataFrame(data,index=[0])
  return feature

df=user_input_parameters()
st.subheader('User Input Parameters')
st.write(df)

diabities=Data
diabities=Data.dropna()

#Split the Data
X=diabities.drop(['class','Genital thrush','Itching','Irritability','delayed healing','Muscle weakness','muscle stiffness','Obesity'],axis=1) #Independent Variable
Y=diabities['class'] #Dependent Variable

#Match the order
df=df[X.columns]

#Model
Le=LogisticRegression()
Le.fit(X,Y)

#Do the predection on the user data
predection=Le.predict(df)
st.subheader('Prediction of Diabities')
st.write(predection)

#Check the accuracy of the data
from sklearn.metrics import accuracy_score
st.subheader('Accuracy of the Model')
st.write(str(accuracy_score(Y,Le.predict(X))*100)+'%')

